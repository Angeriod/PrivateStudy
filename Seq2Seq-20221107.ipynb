{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bca8b79f",
   "metadata": {},
   "source": [
    "https://deep-learning-study.tistory.com/686"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49057945",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchtext.legacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Multi30k\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Field, BucketIterator\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torchtext.legacy'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchtext.legacy.datasets import Multi30k\n",
    "from torchtext.legacy.data import Field, BucketIterator\n",
    "import spacy\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8b3d8fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'random' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1234\u001b[39m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mrandom\u001b[49m\u001b[38;5;241m.\u001b[39mseed(seed)\n\u001b[0;32m      4\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(seed)\n\u001b[0;32m      5\u001b[0m torch\u001b[38;5;241m.\u001b[39mmanual_seed(seed)\u001b[38;5;66;03m#pytorch의 randomseed고정\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'random' is not defined"
     ]
    }
   ],
   "source": [
    "seed=1234\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)#pytorch의 randomseed고정\n",
    "torch.cuda.manual_seed(seed)#pytorch randomseed 고정\n",
    "torch.backend.cudnn.deterministic=True#cudnn randomseed 를 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21e3f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import de_core_news_sm\n",
    "import en_core_web_sm\n",
    "\n",
    "spacy_en= en_core_web_sm.load()\n",
    "spacy_de=de_core_news_sm.load()\n",
    "\n",
    "def tokenize_de(text):\n",
    "    return [tok.text for tok in spacy_de.tokenizer(text)][::-1]\n",
    "\n",
    "def tokenize_en(text):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "SRC=Field(tokenize=tokenize_de, init_token='<sos>', eos_token='<sos>', lower=True)\n",
    "TRG=Field(tokenize=tkenize_en, init_token'<sos>', eos_token='<sos>', lower=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1663e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data=Multi30k.splits(exts=('.de','.en'),fields=(SRC,TRG))\n",
    "# train, validation, test 데이터를 불러오고, 다운로드 합니다.\n",
    "# Multi30k dataset을 사용하여, 30,000개의 영어, 독일, 프랑스어 문장을 포함합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebbc612",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of training examples:{len(train_data.examples)}')\n",
    "print(f'Number of validation examples:{len(valid_data.examples)}')\n",
    "print(f'Number of testing examples:{len(test_data.examples)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0618dcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC.build_vocab(train_data, min_freq=2)\n",
    "TRG.build_vocab(train_data,min_freq=2)\n",
    "#토큰화 전처리가 끝나면, 각단어에 고유한 정수를 맵핑해주는 정수 인코딩작업이 필요하다. 그리고 이 전처리를 위해서는 단어집합이 필요한데, \n",
    "#정의한 filed에 build_vocab을 이용하면 단어집합을 만들수 있다.\n",
    "# min_freq=2는 2번 이상 등장한 토큰을 출력합니다.\n",
    "# 토큰이 1번만 등장했다면 <unk>로 대체합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747b93ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "batch_size=128\n",
    "train_iterator, valid_iterator, test_iterator=BucketIterator.splits((train_data, valid_data, test_data),batch_size=batch_size,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9210e2e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mEncoder\u001b[39;00m(\u001b[43mnn\u001b[49m\u001b[38;5;241m.\u001b[39mModule):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_dim, emb_dim, hid_dim, n_layers, dropout):\n\u001b[0;32m      3\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hid_dim=hid_dim\n",
    "        self.n_layers=n_layers\n",
    "        #임베딩:입력값을 emb_dim벡터로 변경\n",
    "        self.embedding=nn.Embeding(input_dim, emb_dim)\n",
    "        \n",
    "        #embeding을 입력받아 hid_dim크기의 hidden state,cell출력\n",
    "        self.rnn=nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout)\n",
    "        \n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self,src):\n",
    "        #src=[src.len,batch_size]\n",
    "        embedded= self.dropout(self.embedding(src))\n",
    "        #initial hidden state는 제로텐서\n",
    "        outputs, (hidden,cell)=self.rnn(embedded)\n",
    "        # output: [src_len, batch_size, hid dim * n directions]\n",
    "        # hidden: [n layers * n directions, batch_size, hid dim]\n",
    "        # cell: [n layers * n directions, batch_size, hid dim]\n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bab6d8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
