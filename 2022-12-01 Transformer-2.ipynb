{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab5fb770",
   "metadata": {},
   "source": [
    "https://github.com/bentrevett/pytorch-seq2seq/blob/master/6%20-%20Attention%20is%20All%20You%20Need.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bbf228",
   "metadata": {},
   "source": [
    "https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af0aae87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchtext\n",
    "from torchtext.legacy.datasets import Multi30k\n",
    "from torchtext.legacy.data import Field, BucketIterator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0257f766",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=12\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "431330e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_de = spacy.load('de_core_news_sm')\n",
    "spacy_en = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e85d440",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_de(text):\n",
    "    return [tok.text for tok in spacy_de.tokenizer(text)]\n",
    "\n",
    "def tokenize_en(text):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09394349",
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC=Field(tokenize=tokenize_de, init_token='', eos_token='', lower=True, batch_first=True)\n",
    "TRG=Field(tokenize=tokenize_en, init_token='', eos_token='', lower=True, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a56522e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = Multi30k.splits(exts=('.de', '.en'), fields=(SRC,TRG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f54c637",
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC.build_vocab(train_data, min_freq=2)\n",
    "TRG.build_vocab(train_data, min_freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45824a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "device= torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3937c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=128\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits((train_data, valid_data, test_data), batch_size=BATCH_SIZE, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4449a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hid_dim, n_layers, n_heads, pf_dim, dropout, device, max_length=100):\n",
    "        super().__init__()\n",
    "            \n",
    "        self.device=device\n",
    "        self.tok_embedding=nn.Embedding(input_dim, hid_dim)\n",
    "        self.pos_embedding=nn.Embedding(max_length, hid_dim)\n",
    "        \n",
    "        self.layers=nn.ModuleList([EncoderLayer(hid_dim, n_heads, pf_dim, dropout, device) for _ in range(n_layers)])\n",
    "        \n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "        \n",
    "        self.scale=torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
    "    \n",
    "    def forward(self,src, src_mask):\n",
    "        \n",
    "        \n",
    "        #src=[src len, batch_size]\n",
    "        #src mask=[batch size, 1, 1, src len]\n",
    "        \n",
    "        batch_size=src.shape[0]\n",
    "        src_len=src.shape[1]\n",
    "        \n",
    "        pos= torch.arange(0, src_len).unsqueeze(0).repeat(batch_size,1).to(self.device)\n",
    "        src= self.dropout((self.tok_embedding(src)*self.scale) + self.pos_embedding(pos))\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            src=layer(src, src_mask)\n",
    "            \n",
    "        return src\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea39d9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, hid_dim, n_heads, pf_dim, dropout, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.self_attn_layer_norm=nn.LayerNorm(hid_dim)\n",
    "        self.ff_layer_norm=nn.LayerNorm(hid_dim)\n",
    "        self.self_attention=MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
    "        self.positionwise_feedforward=PositionwiseFeedforwardLayer(hid_dim, pf_dim, dropout)\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src, src_mask):\n",
    "        \n",
    "        _src, _ =self.self_attention(src, src, src, src_mask)\n",
    "        \n",
    "        src=self.self_attn_layer_norm(src+self.dropout(_src))\n",
    "        \n",
    "        _src=self.positionwise_feedforward(src)\n",
    "        \n",
    "        src=self.ff_layer_norm(src+self.dropout(_src))\n",
    "        \n",
    "        return src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b08bf4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiheadAttentionLayer(nn.Module):\n",
    "    def __init__(self, hid_dim, n_heads, dropout, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        assert hid_dim % n_heads== 0\n",
    "        \n",
    "        self.hid_dim=hid_dim\n",
    "        self.n_heads=n_heads\n",
    "        self.head_dim=hid_dim//n_heads\n",
    "        \n",
    "        self.fc_q=nn.Linear(hid_dim, hid_dim)\n",
    "        self.fc_k=nn.Linear(hid_dim, hid_dim)\n",
    "        self.fc_v=nn.Linear(hid_dim, hid_dim)\n",
    "        \n",
    "        self.fc_o=nn.Linear(hid_dim, hid_dim)\n",
    "        \n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "        \n",
    "        self.scale=torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
    "        \n",
    "        \n",
    "    def forward(self ,query, key, value, mask=None):\n",
    "        \n",
    "        batch_zie=query.shape[0]\n",
    "        #query = [batch_size, qyery len, hid_dim]\n",
    "        #key= [batch_size, key len, hid_dim]\n",
    "        #value=[batch size, value len, hid _dim]\n",
    "        \n",
    "        Q=self.fc_q(query)\n",
    "        K=self.fc_k(key)\n",
    "        V=self.fc_v(value)\n",
    "        \n",
    "        #Q = [batch size, query len, hid _dim]\n",
    "        #K= [batch size, key len, hid dim]\n",
    "        #V= [batch size, value len , hid_dim]\n",
    "        \n",
    "        Q=Q.view(batch_size, -1, self.n_heads, self.hid_dim ).permute(0,2,1,3)\n",
    "        K=K.view(batch_size, -1, self.n_heads, self.hid_dim).permute(0,2,1,3)\n",
    "        V=V.view(batch_size, -1, self.n_heads, self.hid_dim).permute(0,2,1,3)\n",
    "        \n",
    "        #Q=[batch_size, n_heads, query len, hid_dim]\n",
    "        #K=[batch_size, n_heads, Key len, hid_dim]\n",
    "        #V=[batch_size, n_heads, value len, hid_dim]\n",
    "        \n",
    "        energy=torch.matmul(Q, K.permute(0,1,3,2)) / self.scale \n",
    "        #  batch와 n_heads는 아마도 작용 x ,[query_len, hid_dim]*[hid_dim, key_len]\n",
    "        #energy= [batch size, n_heads, query len ,key len]\n",
    "        \n",
    "        if mask is not None:\n",
    "            energy = energy.masked_fill(mask==0, -1e10)\n",
    "            \n",
    "        attention=torch.softmax(energy, dim=-1)\n",
    "        \n",
    "        #attention= [batch size, n_heads, query len , key len]\n",
    "        \n",
    "        x=torch.matmul(self.dropout(attention), V)\n",
    "        \n",
    "        #x=[batch size, n_heads, query len, head_dim]\n",
    "        x=x.permute(0,2,1,3).contiguous() # 메모리주소가 axis=0으로 저장되게 contiguous()를 써서 적용\n",
    "        #x=[batch_size, n heads, query len, head dim]\n",
    "        x=x.view(batch_size, -1, self.hid_dim)\n",
    "        #x=[batch size, query len, hid_dim]\n",
    "        x=self.fc_o(x)\n",
    "        #x=[batch size, query len, hid dim]\n",
    "        return x, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24f0fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedforwardLayer(nn.Module):\n",
    "    def __init__(self, hid_dim, pf_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.fc_1=nn.Linear(hid_dim, pf_dim)\n",
    "        self.fc_2=nn.Linear(pf_dim, hid_dim)\n",
    "        \n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x=self."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
